1. Import numpy, pandas, datetime as dt, matplotlib.pyplot, mpl_toolkits.axes_grid1(ImageGrid), os, tqdm , 
    sklearn.metrics import log_loss, accuracy_score
    keras.preprocessing(image), keras.applications.vgg16(VGG16), keras.applications.resnet50(ResNet50)
    keras.applications(xception), keras.applications(inception_v3), 
    keras.applications.vgg16(preprocess_input, decode_predictions
    sklearn.linear_model(LogisticRegression)

2. Define a variable start from dt.datetime.now()

3.  cache_dir = os.expanduser(join('~', '.keras'))
      makedirs(cache_dir); models_dir = join(cache_dir, 'models'); makedirs(models_dir)

4. Define INPUT_SIZE = 224, NUM_CLASSES = 16, SEED=1987.
    data_dir = '../input/dog-breed-identification'
    labels = pd.read_csv(join(data_dir, 'labels.csv'))
    sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))
    print(len(listdir(join(data_dir, 'train'))), len(labels))
    print(len(listdir(join(data_dir, 'test'))), len(sample_submission))

5.  # Count the breeds
   selected_breed_list=list(labels.groupby('breed').count().sort_values(by='id',ascending=False).head(NUM_CLASSES).index)
   labels = labels[labels['breed'].isin(selected_breed_list)]
   labels['target'] = 1
   labels['rank'] = labels.groupby('breed').rank()['id']
   labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)
   np.random.seed(seed=SEED)
   rnd = np.random.random(len(labels))
   train_idx = rnd < 0.8
   valid_idx = rnd >= 0.8
   y_train = labels_pivot[selected_breed_list]
   ytr = y_train[train_idx]
   yv = y_train[valid_idx]

6. # Read and resize Image
    read_img(img_id, train_or_test, size):
	img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)
        img = image.img_to_array(img)
        R img

7. # Pretrained ResNet50 
    model = ResNet50(weights='imagenet')
    j = int(np.sqrt(NUM_CLASSES))
    i = int(np.ceil(1. * NUM_CLASSES / j))
    fig = plt.figure(1, figsize=(16, 16))
    grid = ImageGrid(fig, 111, nrows_ncols=(i, j), axes_pad=0.05)
    for i, (img_id, breed) in enumerate(labels.loc[labels['rank'] == 1, ['id', 'breed]].values):
	ax = grid[i]
	img = read_img(img_id, 'train', (224, 224))
        ax.imshow(img / 255.)
	x = preprocess_input(np.expand_dims(img.copy(), axis=0))
	preds = model.predict(x)
	_, imagenet_class_name, prob = decode_predictions(preds, top=1)[0][0]
       ax.text(10, 180, 'ResNet50: %s (%.2f)' % (imagenet_class_name , prob), color='w', backgroundcolor='k', alpha=0.8)
	ax.text(10, 200, 'LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)
	ax.axis('off')
plt.show()

8. Using VGG bottleneck features
     INPUT_SIZE = 224
     POOLING = 'avg'
     x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')
     for i, img_id in tqdm(enumerate(labels['id'])):
	img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))
	x = preprocess_input(np.expand_dims(img.copy(), axis=0))
	x_train[i] = x
      print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))
      

    Xtr = x_train[train_idx]
    Xvl = X_train[valid_idx]
    print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))
    vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)
     train_vgg_bf = vgg_bottleneck.predict(Xtr, batch_size=32, verbose=1)
     valid_vgg_bf = vgg_bottleneck.predict(Xv, batch_size=32, verbose=1)
     print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))
     print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))

    # LogReg on VGG bottleneck 
     logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)
     logreg.fit(train_vgg_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))
     valid_probs = logreg.predict_proba(valid_vgg_bf)
     valid_preds = logreg.predict(valid_vgg_bf)

     print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))
     print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))

11. # Exception Bottleneck
     INPUT_SIZE = 224
     POOLING = 'avg'
     x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')
     for i, img_id in tqdm(enumerate(labels['id'])):
	img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))
	x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))
	x_train[i] = x
      print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))

    Xtr = x_train[train_idx]
    Xvl = X_train[valid_idx]
    print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))
    xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)
     train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)
     valid_x_bf = xception.predict(Xv, batch_size=32, verbose=1)
     print('VGG train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))
     print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))

     # LogReg on VGG bottleneck 
     logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)
     logreg.fit(train_x_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))
     valid_probs = logreg.predict_proba(valid_x_bf)
     valid_preds = logreg.predict(valid_x_bf)

     print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))
     print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))

12. 
    Xtr = x_train[train_idx]
    Xvl = X_train[valid_idx]
    print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))
    inception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)
     train_i_bf = inception_bottleneck.predict(Xtr, batch_size=32, verbose=1)
     valid_i_bf = inception_bottleneck.predict(Xv, batch_size=32, verbose=1)
     print('VGG train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))
     print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))

     # LogReg on VGG bottleneck 
     logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)
     logreg.fit(train_i_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))
     valid_probs = logreg.predict_proba(valid_x_bf)
     valid_preds = logreg.predict(valid_x_bf)

     print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))
     print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))

13. LogReg on all bottleneck Features
      X = np.hstack([train_x_bf, train_i_bf])
      Y =  np.hstack([valid_x_bf, valid_i_bf])
       print('Full train bottleneck features shape: {} size: {:,}'.format(X.shape, X.size))
       print('Full valid bottleneck features shape: {} size: {:,}'.format(V.shape, V.size))
        logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)
        logreg.fit(X, (ytr * range(NUM_CLASSES)).sum(axis=1))        
	valid_probs = logreg.predict_proba(Y)
        valid_preds = logreg.predict(Y)

        print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))
        print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))

14.  valid_breeds = (yv * range(NUM_CLASSES)).sum(axis=1)
	error_idx = (valid_breeds != valid_preds)
        for img_id, breed, pred in zip(labels.loc[valid_idx, 'id'].values[error_idx], 
						          [selected_breed_list[int(b)] for b in valid_preds[error_idx]],
                                                         [selected_breed_list[int(b)] for b in valid_breeds[error_idx]]):
		fig, ax = plt.subplots(figsize=(5,5))
    		img = read_img(img_id, 'train', (299, 299))
    		ax.imshow(img / 255.)
    		ax.text(10, 250, 'Prediction: %s' % pred, color='w', backgroundcolor='r', alpha=0.8)
    		ax.text(10, 270, 'LABEL: %s' % breed, color='k', backgroundcolor='g', alpha=0.8)
    		ax.axis('off')
    		plt.show()                            

