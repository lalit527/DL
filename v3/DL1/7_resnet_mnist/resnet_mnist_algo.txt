## Resnet MNIST
1. Import vision
2. path - URLs.MNIST; path.ls()
3. il = ImageList.from_folder(path, convert_mode='L')
    il.items[0]
    defaults.cmap = 'binary'
    il
    il[0].show()
    sd = il.split_by_folder(train='training', valid='testing')
    sd
    (path/'training').ls()
    l1 = sd.label_from_folder()
    l1
    x, y = l1.train[0]
    x.show()
    print y, x.shape
4. tfms = ([*rand_pad(padding=3, size=28, mode='zeros')], [])
    l1 = l1.transform(tfms)
    bs =1 28
    data = ll.databunch(bs=bs).normalize()
    x,y = data.train_ds[0]
    x.show()
    print(y)
5. def _plot(i,j,ax): data.train_ds[0][0].show(ax, cmap='gray')
    plot_multi(_plot, 3, 3, figsize=(8,8))
    
    xb,yb = data.one_batch()
    xb.shape,yb.shape

    data.show_batch(rows=3, figsize=(5,5))

6 # Basic CNN with batchnorm
    def conv(ni, nf): return nn.COnv2d(ni, nf, kernel_size=3, stride=2, padding=1)

    model = nn.Sequential(
       conv(1, 8), # 14
       nn.BatchNorm2d(8),
       nn.ReLU(),
       conv(8, 16), # 7
        nn.BatchNorm2d(16),
        nn.ReLU(),
        conv(16, 32), # 4
        nn.BatchNorm2d(32),
        nn.ReLU(),
        conv(32, 16), # 2
        nn.BatchNorm2d(16),
        nn.ReLU(),
        conv(16, 10), # 1
        nn.BatchNorm2d(10),
        Flatten()     # remove (1,1) grid
      )
     
    learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)
    print(learn.summary())

    xb = xb.cuda()
    model(xb).shape
    lr_find(end_lr=100), plot, fit_one_cycle(3, max_lr=0.1)

7. # Refactor
    def conv2(ni,nf): return conv_layer(ni,nf,stride=2)
    model = nn.Sequential(
       conv2(1, 8),   # 14
       conv2(8, 16),  # 7
       conv2(16, 32), # 4
       conv2(32, 16), # 2
       conv2(16, 10), # 1
       Flatten()      # remove (1,1) grid
    )

    Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)
    fit_one_cycle(10, max_lr=0.1)

8. Resnetblock
    class ResBlock - nf
        self.conv1 = conv_layer(nf,nf)
        self.conv2 = conv_layer(nf,nf)
     forward(self, x): return x + self.conv2(self.conv1(x))

     model = nn.Sequential(
    conv2(1, 8),
    res_block(8),
    conv2(8, 16),
    res_block(16),
    conv2(16, 32),
    res_block(32),
    conv2(32, 16),
    res_block(16),
    conv2(16, 10),
    Flatten()
)
    conv_and_res(ni,nf): return nn.Sequential(conv2(ni, nf), res_block(nf))

   model = nn.Sequential(
    conv_and_res(1, 8),
    conv_and_res(8, 16),
    conv_and_res(16, 32),
    conv_and_res(32, 16),
    conv2(16, 10),
    Flatten()
)

    Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)
    lr_find(end_lr=100), recorder.plot()
    fit_one_cycle(12, max_lr=0.05)
    print(learn.summary())

