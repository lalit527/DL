1. Import vision, callbacks, vision.gan
2. path from URLs.PETS
     path_hr path/'images'
     path_lr path/'crappy'
3. define crappify - fn, i
       dest = path_lr/fn.relative_to(path_hr)
       dest.parent.mkdir(parents=True, exist_ok=True)
       img = PIL.Image.open(fn)
       targ_sz = resize_to(img, 96, use_min=True)
       img = img.resize(targ_sz, resampe=PIL.Image.BILINEA).convert('RGB')
       w, h = img.size
       q = random.randint(10, 70)
        ImageDraw.Draw(img).text((random.andint(0, w//2), random.randint(0, h//2)), str(q), fill=(255, 255,255)
        img.save(dest, quality=q)
4. #il = ImageList.from_folder(path_hr)
    #parallel(crappifier(path_lr, path_hr), il.items)
5. bs, size = 32, 128
    arch = models.resnet34
     src = ImageImageList.from_folder(path_lr).split_by_rand_pct(0.1, seed=42)
     define get_data - bs, size
         data = src.label_from_func(lambda x: path_hr/x.name).transform(get_transforms(max_zoom=2.), size, tfm_y)
                     .databunch(bs=bs).normalize(imagenet_stats, do_y=True)
         data.c = 3
         return data

     data_gen = get_data(bs,size)
     data_gen.show_batch(4)
     
     wd = 1e-3
     y_range = (-3., 3.)
     loss_gen = MSELossFlat()
     define create_gen_learner and return unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Weight,self_attention=True, y_range=y_range,loss_func=loss_gen)
     learn_gen = create_gen_learner()
     fit_one_cycle(2, pct_start=0.8)
     unfreeze()
     fit_one_cycle(3, slice(1e-6, 1e-3)
     show_results(rows=4)
     save('gen-pre2')
     load('gen-pre2')
6. name_gen = 'image_gen'
    path_gen = path/name_gen
    path_gen.mkdir(exist_ok=True)
    Define method save_preds(dl):
           i = 0
           names = dl.dataset.items
           for b in dl:
                 preds = learn_gen.pred_batch(batch=b, reconstruct=True)
                 for o in preds:
                      o.save(path_gen/names[i].name
                      i += 1
     save_preds(data_gen.fix_dl)
     PIL.Image.open(path_gen.ls()[0])
     
7. Train critic 
    learn_gen=None
    gc.collect()
    # Pretrain the critic on crappy vs not crappy.
    define method -> get_crit_data - classes, bs, size:
           src = ImageList.from_folder(path, include=classes).split_by_rand_pct(0.1, seed=42)
           l1 = src.label_from_folder(classes=classes)
           data = (l1.transform(get_transforms(max_zoom=2.), size=size)
           .databunch(bs=bs).normalize(imagenet_stats))
           data.c = 3
           return data
    data_crit = get_crit_data([name_gen, 'images'], bs=bs, size=size)
    data_crit.show_batch(rows=3, ds_type=DatasetType.Train, imgsize=3)
    loss_critic = AdaptiveLoss(nn.BCEWithLogitsLoss())
    def create_critic_learner(data, metrics):
         return Learner(data, gan_critic(), metrics=metrics, loss_func=loss_critic, wd=wd)
    learn_critic = create_critic_learner(data_crit, accuracy_thresh_expand)
    fit_one_cycle(6, 1e-3), save('critic-pre2')
8. # GAN
    learn_crit=None
    learn_gen=None
    gc.collect()
    
    data_crit = get_crit_data(['crappy', 'images'], bs=bs, size=size)
    learn_crit = create_critic_learner(data_crit, metrics=None).load('critic-pre2')
    learn_gen = create_gen_learner().load('gen-pre2')

    switcher = partial(AdaptiveGANSwitcher, critic_thresh=0.65)
    learn = GANLearner.from_learners(learn_gen, learn_crit, weights_gen=(1.,50.), show_img=False, switcher=switcher,
                                 opt_func=partial(optim.Adam, betas=(0.,0.99)), wd=wd)
    learn.callback_fns.append(partial(GANDiscriminativeLR, mult_lr=5.))

     lr = 1e-4
     learn.fit(40,lr)
     save('gan-1c')

     learn.data=get_data(16,192)
     fit(10,lr/2)
     show_results(rows=16)
     save('gan-1c')













