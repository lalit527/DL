{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_minibatch_training.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoeTEudbC8n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQsyY-fjDPr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdUzBjZTEBmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import fastai\n",
        "import torch.nn as nn\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujueB_GJHEPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): test(a,b,near)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2-thFCNEEPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLVZ-EkmDxt1",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup\n",
        "\n",
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoW6GNRXDXJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfT9X4Q7D4eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugJO83MsEoVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n, m = x_train.shape\n",
        "c = y_train.max() + 1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAiKjuUKD9Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, n_h, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozk-GrdaEj8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Ed9eNWEl6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcYjAVHGE4he",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKxx929IE9zx",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXcz4MZUFAe9",
        "colab_type": "text"
      },
      "source": [
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MxZRdfEvva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "    return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W-GS4pWFMsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYRZjKaSFZbl",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UziKim5LFPZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "80bf7c5b-9ce1-4020-a4f6-4ac433e8da85"
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU9VFi2fJZ9W",
        "colab_type": "text"
      },
      "source": [
        "Our first three values are 5,0,4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPgenfjmFlrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "965b9315-c475-41ff-a870-9378b3c87dcc"
      },
      "source": [
        "sm_pred[0][5]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.3628, grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6nNM94AJjcZ",
        "colab_type": "text"
      },
      "source": [
        "We can see the probability of the first input being 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKfP4eBhFm9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c2dacf4b-3fc7-4e48-9e36-8f0a4911f1c0"
      },
      "source": [
        "sm_pred[[0,1,2], [5,0,4]]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.3628, -2.3967, -2.1274], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9roUhn2Ju3u",
        "colab_type": "text"
      },
      "source": [
        "We can print multiple probabilities this way. These are probabilities for the first three values being correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10WZ9FShFq8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b5ff4a9f-a15f-4908-98ee-baa17262cb77"
      },
      "source": [
        "y_train.shape[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLo8dn0ZFw3O",
        "colab_type": "text"
      },
      "source": [
        "### Negative log likelihood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeclDowFvhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(inputs, targets):\n",
        "    return -inputs[range(targets.shape[0]), targets].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPuKm7pLF_9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdaYHkiCGCZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3bae4811-36a2-4ad0-856d-560cc7b32fb7"
      },
      "source": [
        "loss"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3164, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A32L1SO7Gvdj",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1QUYggaGDwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o8PQ65JGW9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DurXL-q4KeCs",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rSukCeYKfCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nWcoZmYK2fZ",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87JZnqNgK6wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Xo2EwIK-5y",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our log_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36f73qiK7wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB49RpYZHAoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1MWDE-HVND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOgB0RHGHzzA",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOjZgyDUHZ1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biJ3Pw3MH5SL",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTlTHoLQH1hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t7vN5tMH-l2",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop\n",
        "\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "* get the output of the model on a batch of inputs\n",
        "* compare the output to the labels we have and compute a loss\n",
        "* calculate the gradients of the loss with respect to every parameter of the model\n",
        "* update said parameters with those gradients to make them a little bit better\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_t61tStH3_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-8K6DwFILQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def accuracy(out, yb):\n",
        "    return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjnp5-cHIYIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "035b22e4-7c76-4a66-abfd-0efab32c05f1"
      },
      "source": [
        "bs = 64\n",
        "xb = x_train[0:bs]\n",
        "preds = model(xb)\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3.1093, -3.2875, -2.6611,  3.2415, -6.1680, 11.3483, -0.4206, -0.5457,\n",
              "         -3.1052,  0.6614], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmfMbsSTIfkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "522515a9-a88e-45f9-b76d-521e3d74dfa8"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1566, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt6s2WO2InKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0a0fc22f-8611-4d19-ab86-47f69224bd40"
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9062)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R011G7_RIqIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5   # learning rate\n",
        "epochs = 1 # how many epochs to train for"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00uL1dhIsfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        loss = loss_func(model(xb), yb)\n",
        "        \n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for l in model.layers:\n",
        "                if hasattr(l, 'weight'):\n",
        "                    l.weight -= l.weight.grad * lr\n",
        "                    l.bias   -= l.bias.grad   * lr\n",
        "                    l.weight.grad.zero_()\n",
        "                    l.bias  .grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhN1VGPJJoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "855e8430-a53a-4f54-8e58-da64f1366231"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1566, grad_fn=<NllLossBackward>), tensor(0.9062))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmOv9TqRNbJP",
        "colab_type": "text"
      },
      "source": [
        "## Using parameters and optim\n",
        "\n",
        "**Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfoywnsSN_CJ",
        "colab_type": "text"
      },
      "source": [
        "Use nn.Module.__setattr__ and move relu to functional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHWi2NUoM_TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG_Z5fcmOC3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMP41lWzOEPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d058929a-cf6c-48b9-90f9-1d887e4e0fbe"
      },
      "source": [
        "for name, l in model.named_children():\n",
        "    print(f'{name}: {l}')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywx7uanLOX7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "d5fb084b-7195-40ef-84ce-c3c08292db9a"
      },
      "source": [
        "model"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9tzah-OZAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4e05e25e-8685-4248-f0cb-27e97400669f"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKYMfUacOb9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1) // bs + 1):\n",
        "            start_i = i * bs\n",
        "            end_i = start_i + bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            \n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                    model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6jGc42IPHf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1ET138PIaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "db5fcb73-deb6-4514-90a6-f5b9f8932326"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3129, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fdn9-kjPWqZ",
        "colab_type": "text"
      },
      "source": [
        "PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sydk_0JPM57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in, nh)\n",
        "        self.l2 = nn.Linear(nh, n_out)\n",
        "        \n",
        "    def __setattr__(self, k, v):\n",
        "        if not k.startswith(\"_\"): \n",
        "            self._modules[k] = v\n",
        "        super().__setattr__(k, v)\n",
        "            \n",
        "    def __repr__(self):\n",
        "        return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters():\n",
        "                yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNtFHLILQGrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "863eec97-0757-440c-f5e1-fdc1d86d83f7"
      },
      "source": [
        "mdl = DummyModule(m, nh, 10)\n",
        "mdl"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1S2O7Y0Q5ZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "9055ac89-efb5-43b2-8b8e-2aa9c5b19ee3"
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkHqx7_ARv2F",
        "colab_type": "text"
      },
      "source": [
        "`__setattr__` will be called every time when something is assigned to self. Our `__setattr__` will first check that variable name is not starting with underscore. When there is underscore before a variable it mean that it should be handled as private."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2MC2QWBR4Xm",
        "colab_type": "text"
      },
      "source": [
        "## Registering modules\n",
        "\n",
        "PyTorch have already made this functionality and we can use it by setting nn.Module as parent class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwP5zzDeRhP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ7eR1IIR8ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i, l in enumerate(self.layers):\n",
        "            self.add_module(f'layer_{i}', l)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3g33LD3SY06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7jjykqSbCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "659ae430-79e9-4838-e704-6b1c8e7f1f13"
      },
      "source": [
        "model"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd-QfFHwUBdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4aa3f411-e0a5-48b4-8d30-8db485a27208"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-8065706d4499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-30a077259c10>\u001b[0m in \u001b[0;36mfit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsknR_FZSpXT",
        "colab_type": "text"
      },
      "source": [
        "Next we modify the code so it can take a list of layers,\n",
        "\n",
        "nn.ModuleList\n",
        "nn.ModuleList does this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hL6tB-XSbeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_VlLkg2S4ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQFDngyS6NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "726527cc-5f9d-47d6-f7dd-4adeede18ae0"
      },
      "source": [
        "model"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql0hbcLUS6wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeGByZ8lVIvy",
        "colab_type": "text"
      },
      "source": [
        "**TODO: Validate above**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W_KbaHrVPGV",
        "colab_type": "text"
      },
      "source": [
        "nn.Sequential\n",
        "nn.Sequential is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC87HoXOUrN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBaGpHAgVV6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "64e9480a-9ffe-4f8b-9ec1-4c50ccb9f394"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3411, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5vpLO0xVXuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6207a11d-0dbe-429c-f365-1297f91b7e4a"
      },
      "source": [
        "\n",
        "model"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj6_M1m_Vtn4",
        "colab_type": "text"
      },
      "source": [
        "**optim**\n",
        "\n",
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "    \n",
        "and instead use just:\n",
        "\n",
        "```\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFcGMMY5Vdpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5):\n",
        "        self.params,self.lr = list(params),lr\n",
        "        \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params: p -= p.grad * lr\n",
        "                \n",
        "    def zero_grad(self):\n",
        "        for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzUPtpN9VgA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn18erAHWQ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI5q2PeUWSV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        \n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred,yb)\n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5z_7WlWyLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d845d0c5-fe53-4a2d-c162-755b1ac003c1"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1662, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J014WPmW2d5",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIOvHp_rWz-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BBvpBSSW45h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByvRkc0W6-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c1WO5B0XEzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "58a5733a-af22-46a2-8879-7e860bdbb9f8"
      },
      "source": [
        "\n",
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2822, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rviTHjZDXGAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        \n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred,yb)\n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaCOXpDyXLXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24930aae-97d7-4be8-bfaa-40c4afba9a0a"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3047, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFANWa13XUi1",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnI3x9KuXV5X",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "\n",
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "\n",
        "```\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        " ```\n",
        "Instead, let's do these two steps together, by introducing a Dataset class:\n",
        "\n",
        "```\n",
        "xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXxRhxOoXNU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "    def __init__(self, x, y): \n",
        "        self.x,self.y = x,y\n",
        "    def __len__(self): \n",
        "        return len(self.x)\n",
        "    def __getitem__(self, i): \n",
        "        return self.x[i],self.y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00mRaxrXm9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGxxHSRDXosW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "8d57dba0-dde6-451d-9b22-71f7d0d55356"
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdasKs82Xp98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5u9xlwEXuI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        \n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred,yb)\n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdqw_qExXzUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7650a0da-6d36-4f15-f461-8bc64dbbc211"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0984, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a0gJHd3X5gd",
        "colab_type": "text"
      },
      "source": [
        "DataLoader\n",
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "```\n",
        "for xb,yb in train_dl:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqTrp209X1Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, bs): \n",
        "        self.ds,self.bs = ds,bs\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.ds), self.bs): \n",
        "            yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcepHPIZYS_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfR6zm_0YVEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_BdYx4WYWRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "294a67c2-4ec3-4b7b-fe9f-1b7df8fdda9a"
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7TE0RJqYXqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_axOrAh3Ybu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred,yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-AF_GgvYhk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ef0105fd-c258-4fec-cefd-0a6cfa95ffdb"
      },
      "source": [
        "fit()\n",
        "\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0253, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15nuXnWUYr5O",
        "colab_type": "text"
      },
      "source": [
        "## Random sampling\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inYBZtKeYn5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, bs, shuffle=False):\n",
        "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "        for i in range(0, self.n, self.bs): \n",
        "            yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLoQ5WaGY-Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qru-4eXaY_5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f325fbcd-62ec-44b4-beef-b4730d09292b"
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXLt3HrZZBkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "319474fa-bc37-44d5-d370-d9ce8e59f9db"
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVDF85z8ZCIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e760c733-3d88-4206-8016-a665df316e7a"
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([3, 8, 5]), tensor([7, 4, 0]), tensor([9, 2, 6]), tensor([1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwMOek6GZIJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "    xs, ys = zip(*b)\n",
        "    return torch.stack(xs), torch.stack(ys)\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, ds, sampler, collate_fn=collate):\n",
        "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for s in self.sampler: \n",
        "            yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJZcJ6K0Zen3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXLZxFlpZgOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRWs566TZhzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "4409f247-1fc9-4103-fe22-ac7cfadf677a"
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADXZJREFUeJzt3X+MFPUZx/HPo2IEIYqQIuAp9jBN\njPGgXkxNSaO2GGtIUBOJJjZXID1NNKlaTc3VpEbShDT1R+MfGIwErFatoJEoFiwhBbQx4o8qCiIa\nBM47rogRiBqLPv3j5uyJt99ddmd39njer+Ryu/PszDzZ8GFm9ju3X3N3AYjnmKIbAFAMwg8ERfiB\noAg/EBThB4Ii/EBQhB8IivADQRF+IKjjGrkzM+N2QqDO3N0qeV1NR34zu9TM3jWz7WZ2ey3bAtBY\nVu29/WZ2rKRtkmZK2i3pFUnXuPs7iXU48gN11ogj//mStrv7B+7+paTHJc2uYXsAGqiW8E+WtGvQ\n893Zsm8xs04z22Rmm2rYF4Cc1f0DP3dfLGmxxGk/0ExqOfJ3S2oZ9Py0bBmAYaCW8L8i6SwzO9PM\njpd0taSV+bQFoN6qPu1390NmdqOk1ZKOlbTE3d/OrTMAdVX1UF9VO+OaH6i7htzkA2D4IvxAUIQf\nCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwiK8ANBEX4gqIZO0Y3qtLW1Jes333xzyVpra2ty3VGjRiXrXV1dyfpJJ52UrD///PMlawcOHEiu\ni/riyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQdU0S6+Z7ZB0QNJXkg65e3uZ1zNL7xBGjx6drO/c\nuTNZP/nkk/NsJ1fd3d0la6n7EyRp+fLlebcTQqWz9OZxk89F7r43h+0AaCBO+4Ggag2/S1pjZq+a\nWWceDQFojFpP+2e4e7eZfU/SC2a21d3XD35B9p8C/zEATaamI7+7d2e/+yQ9Len8IV6z2N3by30Y\nCKCxqg6/mZ1oZmMGHku6RNLmvBoDUF+1nPZPkPS0mQ1s56/u/vdcugJQdzWN8x/xzhjnH9KYMWOS\n9VWrViXrH3/8ccna66+/nlx3+vTpyfoZZ5yRrLe0tCTrI0eOLFnbs2dPct0LLrggWS+3flSVjvMz\n1AcERfiBoAg/EBThB4Ii/EBQhB8IiqE+1GT8+PHJ+m233VZVTZLmzp2brC9btixZj4qhPgBJhB8I\nivADQRF+ICjCDwRF+IGgCD8QFFN0oyZ796a/uPnFF18sWSs3zl/uz40Z568NR34gKMIPBEX4gaAI\nPxAU4QeCIvxAUIQfCIpxftRk7NixyXpXV1fV2540aVLV66I8jvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EFTZ7+03syWSZknqc/dzsmWnSHpC0hRJOyTNcfdPyu6M7+0fdtra2pL1J598MlmfOnVqydq2\nbduS686cOTNZ37VrV7IeVZ7f279U0qWHLbtd0lp3P0vS2uw5gGGkbPjdfb2kfYctni1p4GtUlkm6\nPOe+ANRZtdf8E9y9J3vcK2lCTv0AaJCa7+13d09dy5tZp6TOWvcDIF/VHvn3mNlEScp+95V6obsv\ndvd2d2+vcl8A6qDa8K+U1JE97pD0TD7tAGiUsuE3s8ck/UvSD8xst5nNl7RQ0kwze0/Sz7LnAIaR\nsuP8ue6Mcf6m09HRkazfddddyXpLS0uy/vnnn5eszZo1K7nuunXrknUMLc9xfgBHIcIPBEX4gaAI\nPxAU4QeCIvxAUHx191Fg9OjRJWu33nprct077rgjWT/mmPTxYd++w//m69tmzJhRsrZ169bkuqgv\njvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/EeBpUuXlqxdeeWVNW17+fLlyfp9992XrDOW37w4\n8gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzHwVaW1vrtu1FixYl6y+99FLd9o364sgPBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0GVHec3syWSZknqc/dzsmV3SvqVpP9kL+ty91X1ahJpa9asKVlra2ur\n27al8vcBLFy4sGTto48+qqon5KOSI/9SSZcOsfxed5+W/RB8YJgpG353Xy8pPS0LgGGnlmv+G83s\nTTNbYmZjc+sIQENUG/5FklolTZPUI+nuUi80s04z22Rmm6rcF4A6qCr87r7H3b9y968lPSjp/MRr\nF7t7u7u3V9skgPxVFX4zmzjo6RWSNufTDoBGqWSo7zFJF0oab2a7Jf1e0oVmNk2SS9oh6bo69gig\nDszdG7czs8btLJCRI0eWrD3yyCPJdc8777xk/fTTT6+qpwG9vb0la3Pnzk2uu3r16pr2HZW7WyWv\n4w4/ICjCDwRF+IGgCD8QFOEHgiL8QFAM9R3lTjjhhGT9uOPSt3rs378/z3a+5YsvvkjWb7nllmT9\ngQceyLOdowZDfQCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb5kXTuuecm6/fee2+yftFFF1W97507\ndybrU6ZMqXrbRzPG+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzN4FRo0Yl65999lmDOjlyY8em\np2lcsmRJydrs2bNr2vfkyZOT9Z6enpq2P1wxzg8gifADQRF+ICjCDwRF+IGgCD8QFOEHgkp/absk\nM2uR9LCkCZJc0mJ3/7OZnSLpCUlTJO2QNMfdP6lfq8NXa2trsr5x48Zk/bnnnkvWN2/eXLJWbqx7\n/vz5yfqIESOS9XJj7VOnTk3WU95///1kPeo4fl4qOfIfkvQbdz9b0o8k3WBmZ0u6XdJadz9L0trs\nOYBhomz43b3H3V/LHh+QtEXSZEmzJS3LXrZM0uX1ahJA/o7omt/MpkiaLullSRPcfeC8q1f9lwUA\nhomy1/wDzGy0pBWSbnL3/Wb/v33Y3b3Ufftm1imps9ZGAeSroiO/mY1Qf/AfdfenssV7zGxiVp8o\nqW+odd19sbu3u3t7Hg0DyEfZ8Fv/If4hSVvc/Z5BpZWSOrLHHZKeyb89APVSyWn/jyX9QtJbZvZG\ntqxL0kJJfzOz+ZI+lDSnPi0Of1dddVWyfuqppybr8+bNy7OdIzL48m4otfxJ+MGDB5P166+/vupt\no7yy4Xf3jZJK/Qv4ab7tAGgU7vADgiL8QFCEHwiK8ANBEX4gKMIPBFXx7b2o3rhx44puoW5WrFiR\nrC9YsKBkra9vyJtCv9Hb21tVT6gMR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIopuhug3NdfX3zx\nxcn6tddem6xPmjSpZO3TTz9NrlvO/fffn6xv2LAhWT906FBN+8eRY4puAEmEHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4/zAUYZxfgBJhB8IivADQRF+ICjCDwRF+IGgCD8QVNnwm1mLma0zs3fM7G0z+3W2\n/E4z6zazN7Kfy+rfLoC8lL3Jx8wmSpro7q+Z2RhJr0q6XNIcSQfd/U8V74ybfIC6q/Qmn7Iz9rh7\nj6Se7PEBM9siaXJt7QEo2hFd85vZFEnTJb2cLbrRzN40syVmNrbEOp1mtsnMNtXUKYBcVXxvv5mN\nlvRPSX9w96fMbIKkvZJc0gL1XxrMK7MNTvuBOqv0tL+i8JvZCEnPSlrt7vcMUZ8i6Vl3P6fMdgg/\nUGe5/WGPmZmkhyRtGRz87IPAAVdI2nykTQIoTiWf9s+QtEHSW5K+zhZ3SbpG0jT1n/bvkHRd9uFg\nalsc+YE6y/W0Py+EH6g//p4fQBLhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwiK8ANBEX4gqLJf4JmzvZI+HPR8fLasGTVrb83al0Rv1cqztzMqfWFD/57/Ozs32+Tu7YU1kNCs\nvTVrXxK9Vauo3jjtB4Ii/EBQRYd/ccH7T2nW3pq1L4neqlVIb4Ve8wMoTtFHfgAFKST8Znapmb1r\nZtvN7PYieijFzHaY2VvZzMOFTjGWTYPWZ2abBy07xcxeMLP3st9DTpNWUG9NMXNzYmbpQt+7Zpvx\nuuGn/WZ2rKRtkmZK2i3pFUnXuPs7DW2kBDPbIand3QsfEzazn0g6KOnhgdmQzOyPkva5+8LsP86x\n7v7bJuntTh3hzM116q3UzNK/VIHvXZ4zXuehiCP/+ZK2u/sH7v6lpMclzS6gj6bn7usl7Tts8WxJ\ny7LHy9T/j6fhSvTWFNy9x91fyx4fkDQws3Sh712ir0IUEf7JknYNer5bzTXlt0taY2avmlln0c0M\nYcKgmZF6JU0ospkhlJ25uZEOm1m6ad67ama8zhsf+H3XDHf/oaSfS7ohO71tSt5/zdZMwzWLJLWq\nfxq3Hkl3F9lMNrP0Ckk3ufv+wbUi37sh+irkfSsi/N2SWgY9Py1b1hTcvTv73SfpafVfpjSTPQOT\npGa/+wru5xvuvsfdv3L3ryU9qALfu2xm6RWSHnX3p7LFhb93Q/VV1PtWRPhfkXSWmZ1pZsdLulrS\nygL6+A4zOzH7IEZmdqKkS9R8sw+vlNSRPe6Q9EyBvXxLs8zcXGpmaRX83jXdjNfu3vAfSZep/xP/\n9yX9rogeSvT1fUn/zn7eLro3SY+p/zTwv+r/bGS+pHGS1kp6T9I/JJ3SRL39Rf2zOb+p/qBNLKi3\nGeo/pX9T0hvZz2VFv3eJvgp537jDDwiKD/yAoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwT1P0/h\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7vULre4ZkUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "7c6a8772-2b1e-4d78-d392-5af2c0605317"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldSjEofJaNJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "cfa3b22d-2f9e-4001-e209-4559427b533f"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EtFGX6pKMMvFWX4paIMv1TU/wPuGNzZyjypAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f57qIZt0aPZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d854b1b7-1c1c-44ae-ff22-d2bdcb8cf8f7"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0983, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyy9d8ebaU0z",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzoBmZtJaRky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzFPE6W9aXN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-pks-6Wad9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(train_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N73WJOTHafiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f75c0e30-4f8d-4e27-b571-dd09335d3477"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2784, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0QCYxmxansg",
        "colab_type": "text"
      },
      "source": [
        "Most of the time we dont need our own sampler or collate function which is why we can just use the defaults by setting shuffle=true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oerHAR-nagvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-5SAsSIapfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(train_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6l1XcRHaqmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a0f1640-f15a-4774-c979-3d6b7ba36f2d"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0661, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7WVpF7ba0ae",
        "colab_type": "text"
      },
      "source": [
        "## Validation\n",
        "\n",
        "The final thing we want to do is to use validation set. We do this by adding another loop after the training loop where we keep track of loss and accuracy. We dont calculate gradients inside this loop because we dont want to use validation set for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICd7MUazasPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "#         print(model.training)\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                tot_loss += loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZO77F5HbDXR",
        "colab_type": "text"
      },
      "source": [
        "model.train() and model.eval() looks something complicated but it only sets training parameter inside the model object to true or false. Why we need this? Some layers have different kind of behavior whether it is training or testing. For example dropout is not dropping any values when we are doing validation because that would be just stupid.\n",
        "\n",
        "One big problem in implementation above is that the valid is not calculating average reward and average loss correctly when batch size varies.\n",
        "\n",
        "\n",
        "**Question:** Why we need to zero our gradients in PyTorch? If we dont zero the gradients in every loop it is going to add the new gradients to the old ones. Then why cant PyTorch just zero the grads automatically? This is because sometimes we want to use multiple different modules and if PyTorch would automatically zero the gradients we couldnt do this. One important implementation of this is that we can use bigger batch sizes than our computer could normally use. For example if your computer can run certain model with batch size of 32 using this it could run as big batch size as you want. It is not faster but it is updating the weights the same way bigger batch size would do. For example if we use batch size of 32 and zero the gradients only every other loop it is updating the weights same way 64 batch size would do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX7mZKQRa9dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I25O7mptbb2U",
        "colab_type": "text"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDwSAjNWbXDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6a134afe-d021-46bc-8f88-9f660c4fc506"
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.3742) tensor(0.8843)\n",
            "1 tensor(0.2323) tensor(0.9286)\n",
            "2 tensor(0.1073) tensor(0.9696)\n",
            "3 tensor(0.1020) tensor(0.9695)\n",
            "4 tensor(0.1150) tensor(0.9658)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hDYgDYibdsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}