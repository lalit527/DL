{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_fully_connected.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w61EPN1vYsjp",
        "colab_type": "text"
      },
      "source": [
        "# Fully Connected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhYuvMfcYxCz",
        "colab_type": "text"
      },
      "source": [
        "### The Forward and backward passes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsW3spW8oAK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import fastai\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k089qxq24yin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): test(a,b,near)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-X5LikRji7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgESqM3AZAev",
        "colab_type": "text"
      },
      "source": [
        "- First we normalize the datasets. Important thing to notice is that we use training set values also for validation set. Normalizing dataset just mean that mean of dataset will be 0 and standard deviation will be 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQQBVnZnprR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x, m, s):\n",
        "    return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CAp_Iudnvmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLmjGibQoCz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "88977303-3969-4775-a993-dabb251f372b"
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6mZVra8od2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QerzsBALoiJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f64df9dd-4dfa-4a57-8e07-9854bc1cc170"
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9oaxv4go3RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_near_zero(a, tol=1e-3):\n",
        "    assert a.abs()<tol, f'Near zero: {a}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx4iAY9BwDrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-TFb0gNwF5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f4ae7efb-0d90-4bc7-8407-f8c93828534e"
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0O87C9wXmo",
        "colab_type": "text"
      },
      "source": [
        "## Basic Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKDznazLZRNw",
        "colab_type": "text"
      },
      "source": [
        "- we will create a simple NN with one hidden layer and one output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQzw2vTPwIDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHgwe0DSZSjA",
        "colab_type": "text"
      },
      "source": [
        "- simplified kaiming init / he init\n",
        "    - By dividing with math.sqrt(m) values after the first and the second layer will be also normalized. This is a very important thing to make models work well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGiK8I9twaDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7SEHsLGwbZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkBCYK_8wfMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e88f4a11-9b0f-4631-817d-68e76c8319b7"
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_valid.mean(),x_valid.std()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVl9yx39ZpnG",
        "colab_type": "text"
      },
      "source": [
        "- The mean of dataset should be 0 and the standard deviation 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAull4mewl7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x, w, b):\n",
        "    return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phR1QToUw17E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK1UGsWkw4c7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ed9765ad-9392-48b9-e464-739a8c054031"
      },
      "source": [
        "#...so should this, because we used kaiming init, which is designed to do this\n",
        "t.mean(), t.std()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0300), tensor(0.9758))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1qcVLVkw82Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "    return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57A3PRqsxKXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hot9LByVxP0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "609783d4-8d8e-49d7-dcf2-e0d491d19b70"
      },
      "source": [
        "t.mean(), t.std()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4012), tensor(0.5932))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2opoo5aHHl",
        "colab_type": "text"
      },
      "source": [
        "- These are still 0 and 1 after the first layer because we divide with math.sqrt(m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez4jjh5LaM30",
        "colab_type": "text"
      },
      "source": [
        "**Issue with Relu and BN**\n",
        "- The problem is that ReLU change mean and standard deviation\n",
        "- if we remove everything under zero the new data points can’t have mean of 0 or standard deviation of 1.\n",
        "- Standard deviation will halve every layer which means that there is not much left after a couple of layers. We solve this problem by dividing 2 with m.\n",
        "\n",
        "    `math.sqrt(2/m)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEGShfNYxRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W037mupcxpbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d3428d68-92ab-4a58-c9c2-54019bfaffe4"
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0005), tensor(0.0507))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS3GtMqtxrSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a16b7d5f-1094-46e4-9897-a11c0a88e596"
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5239), tensor(0.8329))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C5XDUgAa4Nb",
        "colab_type": "text"
      },
      "source": [
        "#### These things are already implemented in PyTorch so we can now use those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQ5uvwqxxGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74R5iqRNx6mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqERDQaia_nM",
        "colab_type": "text"
      },
      "source": [
        "- fan_out vs. fan_in means that either you divide by the square root of m or the square root of nh And what is the difference? When we use m it will give the variance of 1 during forward pass but when we use nh the variance will be 1 during backward pass. fan_out is same as using nh so why are we using it and how it can be the same as using m ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZslecUDwx-Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.kaiming_normal_??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNqUxG8yDJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "123b96db-2e28-4300-fbe6-e9d50e6cdf1f"
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4.0896e-05), tensor(0.0504))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rqsb6SDyTB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fd10043a-fc68-4b2a-dc64-e0743754d86d"
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5577), tensor(0.7994))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRT6Bu_wyaD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d0fb3781-5066-4df8-cd24-173ef0f587c5"
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lA72iRoyh6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2iOLaDSykm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f0ecc38a-705d-4184-fbd7-cdeeb71747c1"
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATlETbFSbcBR",
        "colab_type": "text"
      },
      "source": [
        "- The reason to question above is that PyTorch changes the dimensions so we need to think this backwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60-ae4otymD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXSb_v1AypbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS92rgQjywhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhoswQNUy8mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1iKsoInzCB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what if...?\n",
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IC4_3-LzHZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "67d7caa4-d38a-40dd-9eb3-db4ac5ac5835"
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0137), tensor(0.7944))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kjlz2yGzKKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "    l1 = lin(xb, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    l3 = lin(l2, w2, b2)\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INktE4VvzNVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "472eb13f-1dcf-4f01-f59c-13f5ca508122"
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 18.9 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbrzKQa7zO4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGuqSztIzQtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2cba66d4-b668-4778-ef5b-a93ae4042196"
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO2uMi5ezUN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_UMUsQbpkT",
        "colab_type": "text"
      },
      "source": [
        "- .squeeze() will get rid of all unit (size of 1) axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuePawfHzY8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfA2N2O6zbbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U_pJOFYzmaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dd77660c-ce3c-4d10-a242-5558d623aa0b"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PJUiS2pznNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "da34db9b-b874-4923-fa00-5fc9fc735622"
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25.6745)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idxWc2Bizrun",
        "colab_type": "text"
      },
      "source": [
        "## Gradients and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Xg3UKfb9kn",
        "colab_type": "text"
      },
      "source": [
        "- The derivative of something² is just 2*something. The input of the mse is the same as the output of the previous layer. This way gradient can be stored to the input and used later on the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_4Vm5pyzpJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ):\n",
        "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUE_lVOecB-a",
        "colab_type": "text"
      },
      "source": [
        "- The previous layer use gradient calculated above to multiply it with ReLU’s gradient. ReLU’s gradient is just 0 when less than or equal to zero else 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtiMo-TKz57c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ3UvaVfcPGO",
        "colab_type": "text"
      },
      "source": [
        "- The same thing is done for the linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntmIzPNP0J5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    inp.g = out.g @ w.t()\n",
        "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "    b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwpdvID_cV5d",
        "colab_type": "text"
      },
      "source": [
        "- We combine forward pass to backward pass and get following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooatAPsi0cHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "    l1 = inp @ w1 + b1\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w2 + b2\n",
        "    \n",
        "    loss = mse(out, targ)\n",
        "    \n",
        "    mse_grad(out, targ)\n",
        "    lin_grad(l2, out, w2, b2)\n",
        "    relu_grad(l1, l2)\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abJxtD0G0t8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVL_ygv20vP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save for testing against later\n",
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig  = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUcmcrqW3FGj",
        "colab_type": "text"
      },
      "source": [
        "We cheat a little bit and use PyTorch autograd to check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz59ERSq3Ca0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wIiH0P-3ITU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "    l1 = inp @ w12 + b12\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w22 + b22\n",
        "    return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFPEZ9Ww4ZUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE_6sq1S4cE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iYLMHIw4eAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w22.grad, w2g)\n",
        "test_near(b22.grad, b2g)\n",
        "test_near(w12.grad, w1g)\n",
        "test_near(b12.grad, b1g)\n",
        "test_near(xt2.grad, ig )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFGAlSXw5Gh_",
        "colab_type": "text"
      },
      "source": [
        "## Refactor Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FNocqlYcysV",
        "colab_type": "text"
      },
      "source": [
        "#### Layers as classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxhkShFt4hJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)-0.5\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpMu0nn15cxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): \n",
        "        self.w,self.b = w,b\n",
        "    \n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp @ self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCTSp4Zq6Wcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP-eIfoB6rQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers):\n",
        "            l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CofsZwpsMCIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g, b1.g, w2.g, b2.g = [None] * 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yThWV9MMIlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J3t_E3VMJas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3437b520-7c0c-4ede-da02-185b5df2ebac"
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 114 ms, sys: 210 µs, total: 114 ms\n",
            "Wall time: 115 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWedNFnVMXsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b72759e9-0920-4c8f-aa3d-eb43f2d86aac"
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.17 s, sys: 6.48 s, total: 9.65 s\n",
            "Wall time: 9.67 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EdQiO0QMgfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hXNHOIjdMcU",
        "colab_type": "text"
      },
      "source": [
        "#### Module.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_cfUOvdNF14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "    \n",
        "    def forward(self): raise Exception('Not Implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP_kGd9UNgEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.) - 0.5\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSn7TccVN8Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinX8QZaOarf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward(self, inp, targ):\n",
        "        return (inp.squeeze() - targ).pow(2).mean()\n",
        "    \n",
        "    def bwd(self, out, inp, targ):\n",
        "        inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuYkmYS1O7Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiJV3sV6PafN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DlxB1RLPiBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "07fb973c-7456-43e1-8d11-23abc877941e"
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 116 ms, sys: 468 µs, total: 116 ms\n",
            "Wall time: 117 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhsaXsYtPloc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61d3e939-afae-4f42-bf1f-399581faa50f"
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 247 ms, sys: 9.53 ms, total: 256 ms\n",
            "Wall time: 259 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylGDbP6xQI68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlCNGPGhQNoS",
        "colab_type": "text"
      },
      "source": [
        "## Without einsum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baFEAlNkQMAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ out.g\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDrD0lFtQZWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm1ZdRZ9Qgy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fj1boOeQjL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6429f74f-4ce8-488f-cfb5-cae015a9b64a"
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 111 ms, sys: 1.44 ms, total: 112 ms\n",
            "Wall time: 115 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYRogXz0Qmsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dc490c29-694b-4792-b90e-c3789198accb"
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 235 ms, sys: 5.08 ms, total: 240 ms\n",
            "Wall time: 242 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWteRBvmQpNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Rt8ImWQz9g",
        "colab_type": "text"
      },
      "source": [
        "## nn.Linear and nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZI8hnoiQufI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLthjmpZQ2Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IihV7bmLQ7gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXUrTCsZQ-TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e93c1bc5-3547-416c-a881-19460ddd8aa6"
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 98.8 ms, sys: 397 µs, total: 99.2 ms\n",
            "Wall time: 114 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRVwof6xRDll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "55a7d855-bd6d-4b93-f8b5-0882f13da5e6"
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 78.6 ms, sys: 1.26 ms, total: 79.8 ms\n",
            "Wall time: 85 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5QXnEhRFf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}